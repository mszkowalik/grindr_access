{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "from mongoengine import connect, NotUniqueError\n",
    "connect(\n",
    "    db=os.getenv('MONGO_DB'),\n",
    "    host=os.getenv('MONGO_URL'),\n",
    "    port=27017,\n",
    "    username=os.getenv('MONGO_USR'),\n",
    "    password=os.getenv('MONGO_PWD'),\n",
    "    authentication_source=\"admin\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profile_model import ProfileModel, LocationHistoryModel\n",
    "from mongoengine import connect, Document, LongField, StringField\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from stalkr import select_indexes, localizeProfile, visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_millis = int(time.time() * 1000)\n",
    "\n",
    "# 1 hour ago in milliseconds\n",
    "one_hour_ago_millis = current_millis - 0.2 * (60 * 60 * 1000)\n",
    "\n",
    "# Aggregation pipeline to filter, group by batch_timestamp, and collect profileIds\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$match\": {\n",
    "            \"batch_timestamp\": {\"$gt\": one_hour_ago_millis}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$group\": {\n",
    "            \"_id\": \"$batch_timestamp\",  # Grouping by batch_timestamp\n",
    "            \"profileIds\": {\"$addToSet\": \"$profileId\"}  # Collecting unique profileIds for each batch_timestamp\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\": {\"_id\": 1}  # Optional: Sorting by batch_timestamp if needed\n",
    "    }\n",
    "]\n",
    "\n",
    "results = ProfileModel.objects.aggregate(*pipeline)\n",
    "\n",
    "# Processing the results to use batch_timestamp as key in a dictionary\n",
    "grouped_profile_ids = {result['_id']: result['profileIds'] for result in results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grouped_profile_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m locations \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_timestamp, profile_ids \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgrouped_profile_ids\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch Timestamp: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_timestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Profile IDs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprofile_ids\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Now, for each profile_id, query documents with the matching profile_id and batch_timestamp\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grouped_profile_ids' is not defined"
     ]
    }
   ],
   "source": [
    "locations = {}\n",
    "for batch_timestamp, profile_ids in grouped_profile_ids.items():\n",
    "    print(f\"Batch Timestamp: {batch_timestamp}, Profile IDs: {profile_ids}\")\n",
    "    # Now, for each profile_id, query documents with the matching profile_id and batch_timestamp\n",
    "    for profile_id in profile_ids:\n",
    "        matching_documents = ProfileModel.objects(\n",
    "            batch_timestamp=batch_timestamp,\n",
    "            profileId=profile_id\n",
    "        )\n",
    "        # You can convert the QuerySet to a list of dictionaries if needed\n",
    "        profiles = list(matching_documents.as_pymongo())\n",
    "        new_locations, profile = localizeProfile(profiles)\n",
    "        if profile:\n",
    "            try:\n",
    "                profile.save()  # Attempt to save the new profile\n",
    "            except NotUniqueError:\n",
    "                print(\"A document with the same unique index already exists. Ignoring.\")\n",
    "\n",
    "        locations.update(new_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(locations[613297361])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
